__import__: 
   - experiments/defaults.yaml

env: "FetchPickAndPlaceConstruction"
env_params:
  sparse: false
  shaped_reward: false
  num_blocks: 4
  stack_only: false
  case: "PickAndPlace"
  visualize_target: true
  visualize_mocap: false

rollout_params:
  render: false
  render_initial: false
  render_eval: false
  record: false
  only_final_reward: false
  use_env_states: true
  logging: true
  task_horizon: 400

controller: "mpc-icem-torch"
controller_params:
  horizon: 30
  num_simulated_trajectories: 128
  factor_decrease_num: 1
  cost_along_trajectory: "best"
  use_env_reward: false
  action_sampler_params: 
    opt_iterations: 3
    elites_size: 10
    alpha: 0.1
    init_std: 0.5
    relative_init: true
    execute_best_elite: true
    keep_previous_elites: true
    shift_elites_over_time: false
    finetune_first_action: false
    fraction_elites_reused: 0.3
    use_mean_actions: true
    colored_noise: true
    noise_beta: 3.5
    use_ensemble_cost_std: false
  verbose: false
  do_visualize_plan: false
  use_async_action: false
  logging: true

initial_controller: "none"
initial_controller_params: {}
initial_number_of_rollouts: 0

number_of_rollouts: 100
training_iterations: 1

append_data: true
append_data_eval: false

checkpoints:
  load: false
  save: true
  save_every_n_iter: 2
  restart_every_n_iter: null

device: "cuda:0"

working_dir: "experiments/results/cee_us/zero_shot/pp"
